One-hot encoding adalah teknik pengkodean kategoris yang umum digunakan dalam pemrosesan data. Mengkutip dari James, G, et al. (2013) teknik ini cocok untuk variabel kategori di mana kategori tidak memiliki urutan atau hubungan yang melekat dengan nilai numeriknya. Ide di balik pengkodean one-hot adalah untuk mewakili setiap kategori sebagai vektor biner yang panjangnya sama dengan jumlah kategori unik dalam variabel tersebut.

\begin{table}[htbp]
    \caption{Sample Encoding Data}
    \centering
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{|c|c|c|c|c|c|c|c|c|}
    \hline
    login\_timestamp\_1 & login\_timestamp\_2 & ip\_address\_1 & ip\_address\_2 & country\_1 & country\_2 & region\_1 & region\_2 & city\_1 \\ \hline
    0 & 1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 \\ \hline
    1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 1 \\ \hline
    \end{tabular}%
    }
    \label{tab:sample_table}
\end{table}


Cara kerja one-hot encoding adalah seperti ditunjukan pada Tabel \ref{tab:sample_table} dengan membuat kolom biner baru untuk setiap kategori dalam kolom kategori. Jika terdapat N kategori unik, maka akan dibuat N kolom biner baru. 
Setiap kolom biner akan memiliki nilai 1 jika kategori tersebut hadir dalam observasi, dan nilai 0 jika tidak hadir. Dengan demikian, setiap observasi direpresentasikan sebagai vektor biner dengan panjang N, di mana setiap elemen vektor menunjukkan keberadaan atau ketiadaan kategori yang sesuai dalam observasi. Teknik ini memungkinkan model machine learning untuk memahami dan memproses variabel kategori dalam bentuk yang sesuai dengan algoritma yang digunakan, seperti algoritma regresi logistik atau jaringan saraf.

Meskipun memiliki kelebihan, One-Hot Encoding juga memiliki beberapa kekurangan signifikan. Salah satu kekhawatiran utama adalah potensi untuk menghasilkan data berdimensi tinggi. Untuk fitur kategorikal dengan banyak nilai unik, One-Hot Encoding dapat menghasilkan sejumlah besar fitur biner, yang dapat meningkatkan biaya komputasi dan risiko overfitting. Masalah ini terutama terlihat pada dataset dengan kardinalitas tinggi, di mana jumlah fitur biner yang baru dapat menjadi sangat banyak. Selain itu, peningkatan dimensi dapat menyebabkan penggunaan memori yang lebih tinggi, terutama dalam dataset besar dengan banyak variabel kategorikal. Kebutuhan memori tambahan ini dapat mempengaruhi kecepatan dan efisiensi proses pelatihan.
